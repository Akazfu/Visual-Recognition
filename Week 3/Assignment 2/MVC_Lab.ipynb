{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MVC_Lab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Hfn-Yiy1lp5l","colab_type":"text"},"source":["# Lab Assignment 2\n","## With this assignment you will get to know more about gradient descent optimization and writing your own functions with forward and backward (i.e., gradient) passes\n","## You need to complete all the tasks in this notebook in the lab and show you work to the TA. Edit only those portions in the cells where it asks you to do so!"]},{"cell_type":"code","metadata":{"id":"Zp3BetP-d6cB","colab_type":"code","colab":{}},"source":["import torch\n","from torch.autograd import Variable\n","from torch.autograd import Function\n","import torch.nn.functional as F\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"usEoWHBnSJW9","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"MJpovSL8d_-l","colab_type":"text"},"source":["## Huber loss function\n","https://en.wikipedia.org/wiki/Huber_loss"]},{"cell_type":"code","metadata":{"id":"GTp4nNf9d-zg","colab_type":"code","colab":{}},"source":["# A loss function measures distance between a predicted and a target tensor\n","# An implementation of Huber loss function is given below\n","# We will make use of this loss function in gradient descent optimization\n","def Huber_Loss(input,delta):\n","  m = (torch.abs(input)<=delta).detach().float()\n","  output = torch.sum(0.5*m*input**2 + delta*(1.0-m)*(torch.abs(input)-0.5*delta))\n","  return output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZoxXPadgk-O","colab_type":"text"},"source":["# Test Huber loss with a couple of different examples"]},{"cell_type":"code","metadata":{"id":"KYO_KmUQfmnm","colab_type":"code","outputId":"99132302-059b-47db-f8b4-dbe94691db76","executionInfo":{"status":"ok","timestamp":1569616181068,"user_tz":360,"elapsed":629,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["a = torch.tensor([[0.3, 2.0, -3.1],[0.5, 9.2, 0.1]])\n","print(a.numpy())\n","ha = Huber_Loss(a,1.0)\n","print(ha.numpy())\n","\n","b = torch.tensor([0.3, 2.0])\n","print(b.numpy())\n","hb = Huber_Loss(b,1.0)\n","print(hb.numpy())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[[ 0.3  2.  -3.1]\n"," [ 0.5  9.2  0.1]]\n","12.974999\n","[0.3 2. ]\n","1.545\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26wLACTj7FkG","colab_type":"text"},"source":["# Gradient descent code\n","## Study the following generic gradient descent optimization code.\n","## Huber loss f measures the distance between a probability vector `z` and target 1-hot vector `target`.\n","## When `f.backward` is called, PyTorch first computes $\\nabla_z f$ (gradient of `f` with respect to `z`), then by chain rule it computes $\\nabla_{var} f = J^{z}_{var} \\nabla_z f$, where $J^{z}_{var}$ is the Jacobian of `z` with respect to `var`.\n","## Next, `optimizer.step()` call adjusts the variable `var` in the opposite direction of $\\nabla_{var} f.$"]},{"cell_type":"code","metadata":{"id":"NLxQgQaD7Krq","colab_type":"code","colab":{}},"source":["def gradient_descent(var,optimizer,softmax,loss,target,nIter,nPrint):\n","  for i in range(nIter):\n","    z = softmax(var)\n","    f = loss(z-target,1.0)\n","    optimizer.zero_grad()\n","    f.backward()\n","    optimizer.step()\n","    if i%nPrint==0:\n","      with np.printoptions(precision=3, suppress=True):\n","        print(\"Iteration:\",i,\"Variable:\", z.detach().numpy(),\"Loss: %0.6f\" % f.item())\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5viWaJpSiDuN","colab_type":"text"},"source":["# Gradient descent with Huber Loss\n","## The following cell shows how `gradient_descent` function can be used.\n","## The cell first creates a target 1-hot vector `y`, where only the 3rd place is on.\n","## It also creates a variable `x` with random initialization and an optimizer.\n","## Learning rate and momentum has been set to 0.1 and 0.9, respectively.\n","## Then it calls `gradient_descent` function."]},{"cell_type":"code","metadata":{"id":"AzRgWv_NiIeQ","colab_type":"code","outputId":"48bff8c1-5832-44d0-d415-e8b2b1de729d","executionInfo":{"status":"ok","timestamp":1569616181456,"user_tz":360,"elapsed":1001,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["y = torch.zeros(10)\n","y[2] = 1.0\n","print(\"Target 1-hot vector:\",y.numpy())\n","x = Variable(torch.randn(y.shape),requires_grad=True)\n","\n","optimizer = torch.optim.SGD([x], lr=1e-1, momentum=0.9) # create an optimizer that will do gradient descent optimization\n","\n","gradient_descent(x,optimizer,F.softmax,Huber_Loss,y,1000,100)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Target 1-hot vector: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","Iteration: 0 Variable: [0.177 0.136 0.043 0.055 0.148 0.11  0.042 0.117 0.141 0.029] Loss: 0.519876\n","Iteration: 100 Variable: [0.008 0.008 0.942 0.005 0.008 0.007 0.004 0.007 0.008 0.003] Loss: 0.001857\n","Iteration: 200 Variable: [0.006 0.006 0.957 0.004 0.006 0.005 0.003 0.005 0.006 0.002] Loss: 0.001020\n","Iteration: 300 Variable: [0.005 0.005 0.964 0.003 0.005 0.004 0.003 0.005 0.005 0.002] Loss: 0.000710\n","Iteration: 400 Variable: [0.004 0.004 0.969 0.003 0.004 0.004 0.002 0.004 0.004 0.002] Loss: 0.000544\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration: 500 Variable: [0.004 0.004 0.972 0.003 0.004 0.004 0.002 0.004 0.004 0.002] Loss: 0.000441\n","Iteration: 600 Variable: [0.003 0.003 0.974 0.002 0.003 0.003 0.002 0.003 0.003 0.001] Loss: 0.000371\n","Iteration: 700 Variable: [0.003 0.003 0.976 0.002 0.003 0.003 0.002 0.003 0.003 0.001] Loss: 0.000319\n","Iteration: 800 Variable: [0.003 0.003 0.978 0.002 0.003 0.003 0.002 0.003 0.003 0.001] Loss: 0.000281\n","Iteration: 900 Variable: [0.003 0.003 0.979 0.002 0.003 0.003 0.002 0.003 0.003 0.001] Loss: 0.000250\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EtIf2LRqvOph","colab_type":"text"},"source":["# <font color='red'>20% Weight:</font> In this markdown cell, using [math mode](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), write gradient of Huber loss function: $output = \\sum_i 0.5 m_i (input)^{2}_{i} + \\delta (1-m_i)(|input_i|-0.5 \\delta)$ with respect to $input.$ Treat $m_i$ to be independent of $input_i,$ because we replaced *if* control statement with $m_i.$\n","## Your solution <font color='red'>20% (complete formula)</font>: $\\frac{\\partial (output)}{\\partial (input)_i} = m_i (input)_{i} + (1-m_i) \\delta \\frac{input_{i}}{|input_i|}$ "]},{"cell_type":"code","metadata":{"id":"XbKc4omJUKR-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ly8SaBQ-lXbg","colab_type":"text"},"source":["# <font color='red'>20% Weight:</font> Define your own (correct!) rule of differentiation for Huber loss function\n","## Edit indicated line in the cell below. Use the following formula. Do not use for/while/any loop in your solution.\n","## For this function,  chain rule (Jacobian-vector product) takes the following form: $\\frac{\\partial (cost)}{\\partial (input)_i} = \\frac{\\partial (output)}{\\partial (input)_i} \\frac{\\partial (cost)}{\\partial (output)}.$\n","# In the `backward` method below, $\\frac{\\partial (cost)}{\\partial (output)}$ is denoted by `output_grad` and the $i^{th}$ component of `input_grad` is symbolized by $\\frac{\\partial (cost)}{\\partial (input)_i}.$"]},{"cell_type":"code","metadata":{"id":"UX4zC76XlWr0","colab_type":"code","colab":{}},"source":["# Inherit from torch.autograd.Function\n","class My_Huber_Loss(Function):\n","\n","    # Note that both forward and backward are @staticmethods\n","    @staticmethod\n","    def forward(ctx, input, delta):\n","        m = (torch.abs(input)<=delta).float()\n","        ctx.save_for_backward(input,torch.tensor(m),torch.tensor(delta))\n","        output = torch.sum(0.5*m*input**2 + delta*(1.0-m)*(torch.abs(input)-0.5*delta))\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, output_grad):\n","        # retrieve saved tensors and use them in derivative calculation\n","        input, m, delta = ctx.saved_tensors\n","\n","        # Return Jacobian-vector product (chain rule)\n","        # For Huber loss function the Jacobian happens to be a diagonal matrix\n","        # Also, note that output_grad is a scalar, because forward function returns a scalar value\n","        input_grad = (m * input + (1-m) * delta * input / torch.abs(input)) * output_grad # complete this line, do not use for loop\n","        # must return two gradients becuase forward function takes in two arguments\n","        return input_grad, None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WkG5zXGZcgja","colab_type":"text"},"source":["#Gradient Descent on Your Own Huber Loss\n","## You should get almost identical results as before if your rule of differentation is correct!"]},{"cell_type":"code","metadata":{"id":"6DKnFDK0pPjF","colab_type":"code","outputId":"9f236036-c7f1-4696-e6e2-4b28e60a0442","executionInfo":{"status":"ok","timestamp":1569616182066,"user_tz":360,"elapsed":1590,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["y = torch.zeros(10)\n","y[2] = 1.0\n","print(\"Target:\",y.numpy())\n","x = Variable(torch.randn(y.shape),requires_grad=True)\n","\n","optimizer = torch.optim.SGD([x], lr=1e-1, momentum=0.9) # create an optimizer that will do gradient descent optimization\n","\n","gradient_descent(x,optimizer,F.softmax,My_Huber_Loss.apply,y,1000,100)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Target: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","Iteration: 0 Variable: [0.119 0.073 0.084 0.157 0.091 0.097 0.019 0.02  0.058 0.281] Loss: 0.491799\n","Iteration: 100 Variable: [0.008 0.006 0.947 0.008 0.007 0.007 0.002 0.002 0.005 0.008] Loss: 0.001579\n","Iteration: 200 Variable: [0.006 0.005 0.959 0.006 0.005 0.005 0.002 0.002 0.004 0.006] Loss: 0.000936\n","Iteration: 300 Variable: [0.005 0.004 0.966 0.005 0.004 0.005 0.001 0.001 0.003 0.005] Loss: 0.000667\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration: 400 Variable: [0.004 0.004 0.97  0.005 0.004 0.004 0.001 0.001 0.003 0.004] Loss: 0.000517\n","Iteration: 500 Variable: [0.004 0.003 0.973 0.004 0.004 0.004 0.001 0.001 0.003 0.004] Loss: 0.000423\n","Iteration: 600 Variable: [0.004 0.003 0.975 0.004 0.003 0.003 0.001 0.001 0.003 0.004] Loss: 0.000357\n","Iteration: 700 Variable: [0.003 0.003 0.977 0.003 0.003 0.003 0.001 0.001 0.002 0.003] Loss: 0.000309\n","Iteration: 800 Variable: [0.003 0.003 0.978 0.003 0.003 0.003 0.001 0.001 0.002 0.003] Loss: 0.000272\n","Iteration: 900 Variable: [0.003 0.002 0.979 0.003 0.003 0.003 0.001 0.001 0.002 0.003] Loss: 0.000244\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TVpTDS3daNmw","colab_type":"text"},"source":["# <font color='red'>30% Weight:</font> In this markdown cell, using math mode, write Jacobian of softmax function: $(output)_i = \\frac{exp((input)_i)}{ \\sum_k exp((input)_k)}.$\n","## Your solution (<font color='red'>show your derivation to TA</font>): On Paper \n","\\begin{equation*}\n","    \\frac{\\partial (output)_j}{\\partial (input)_i} = \\begin{cases}\n","               (output)_j -(output)_j (output)_i,               & i = j,\\\\\n","               -(output)_j (output)_i, & \\text{otherwise.}\n","           \\end{cases}\n","\\end{equation*}"]},{"cell_type":"markdown","metadata":{"id":"k2K4Q7ePPdfy","colab_type":"text"},"source":["# <font color='red'>30% Weight:</font> Your own softmax with forward and backward functions\n","## Edit indicated line in the cell below. Use the following formula. Do not use for/while/any loop in your solution.\n","## The Jacobian-vector product (chain rule) takes the following form using summation sign: $\\frac{\\partial (cost)}{\\partial (input)_i} = \\sum_j \\frac{\\partial (output)_j}{\\partial (input)_i} \\frac{\\partial (cost)}{\\partial (output)_j}$\n","# Once again note that, in the `backward` method below, $i^{th}$ component of `input_grad` and $j^{th}$ component of `output_grad` are denoted by $\\frac{\\partial (cost)}{\\partial (input)_i}$ and $\\frac{\\partial (cost)}{\\partial (output)_j}$, respectively."]},{"cell_type":"code","metadata":{"id":"zn52-xK_PijV","colab_type":"code","colab":{}},"source":["# Inherit from Function\n","class My_softmax(Function):\n","\n","    # Note that both forward and backward are @staticmethods\n","    @staticmethod\n","    def forward(ctx, input):\n","        output = F.softmax(input,dim=0)\n","        ctx.save_for_backward(output) # this is the only tensor you will need to save for backward function\n","        return output\n","\n","    # This function has only a single output, so it gets only one gradient\n","    @staticmethod\n","    def backward(ctx, output_grad):\n","        output = ctx.saved_tensors[0]\n","        #print('output is', output)\n","        # retrieve saved tensors and use them in derivative calculation\n","        # return Jacobian-vecor product\n","        input_grad = torch.sum((torch.diag(output) - torch.ger(output,output)) * output_grad, 1)  # Complete this line\n","        return input_grad"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fcixVFs4cwHO","colab_type":"text"},"source":["# Gradient Descent on your own Huber Loss and your own softmax"]},{"cell_type":"code","metadata":{"id":"UejqQeb4RZk0","colab_type":"code","outputId":"e7b8aed4-ef51-45dd-f54c-08f7e17d674e","executionInfo":{"status":"ok","timestamp":1569616182455,"user_tz":360,"elapsed":1966,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["y = torch.zeros(10)\n","y[2] = 1.0\n","print(y)\n","x = Variable(torch.randn(y.shape),requires_grad=True)\n","print(x)\n","\n","optimizer = torch.optim.SGD([x], lr=1e-1, momentum=0.9) # create an optimizer that will do gradient descent optimization\n","\n","gradient_descent(x,optimizer,My_softmax.apply,My_Huber_Loss.apply,y,1000,100)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([-0.9612, -0.8806,  0.8634,  0.4036, -1.0341, -1.2295,  0.7396,  0.8960,\n","        -0.4296,  0.0302], requires_grad=True)\n","Iteration: 0 Variable: [0.033 0.036 0.205 0.13  0.031 0.025 0.182 0.212 0.056 0.089] Loss: 0.370637\n","Iteration: 100 Variable: [0.003 0.004 0.949 0.008 0.003 0.003 0.009 0.009 0.005 0.007] Loss: 0.001482\n","Iteration: 200 Variable: [0.003 0.003 0.96  0.006 0.003 0.002 0.007 0.007 0.004 0.005] Loss: 0.000900\n","Iteration: 300 Variable: [0.002 0.002 0.966 0.005 0.002 0.002 0.006 0.006 0.003 0.005] Loss: 0.000647\n","Iteration: 400 Variable: [0.002 0.002 0.97  0.005 0.002 0.002 0.005 0.005 0.003 0.004] Loss: 0.000505\n","Iteration: 500 Variable: [0.002 0.002 0.973 0.004 0.002 0.001 0.005 0.005 0.003 0.004] Loss: 0.000414\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration: 600 Variable: [0.002 0.002 0.975 0.004 0.002 0.001 0.004 0.004 0.003 0.003] Loss: 0.000350\n","Iteration: 700 Variable: [0.002 0.002 0.977 0.004 0.002 0.001 0.004 0.004 0.002 0.003] Loss: 0.000304\n","Iteration: 800 Variable: [0.002 0.002 0.978 0.003 0.001 0.001 0.004 0.004 0.002 0.003] Loss: 0.000268\n","Iteration: 900 Variable: [0.001 0.002 0.979 0.003 0.001 0.001 0.003 0.003 0.002 0.003] Loss: 0.000240\n"],"name":"stdout"}]}]}