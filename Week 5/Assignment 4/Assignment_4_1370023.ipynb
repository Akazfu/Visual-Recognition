{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_StudentID.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8XtcgbGj5xN",
        "colab_type": "text"
      },
      "source": [
        "#Finding optimal hyper-parameters for CIFAR10 Images\n",
        "\n",
        "#Student Name:\n",
        "\n",
        "#Student id:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4BNOnZe46CQ",
        "colab_type": "code",
        "outputId": "568b5e59-cefc-4a4b-821a-e5c8e97cd57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "epochs = 5\n",
        "batch_size_train = 128\n",
        "batch_size_test = 1000\n",
        "learning_rate = 1e-3\n",
        "momentum = 0.5\n",
        "log_interval = 100\n",
        "optimizer_name=\"Adam\"\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# Checking GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWd5IGhbkCnz",
        "colab_type": "text"
      },
      "source": [
        "## Divide CIFAR10 into training, validation and test sets\n",
        "## Use DataLoader iterator for loading data in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2uiYpfC4_aW",
        "colab_type": "code",
        "outputId": "0b5eb93b-da5f-4009-82c4-bc4d93a9460a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "CIFAR10_training = torchvision.datasets.CIFAR10('/CIFAR10_dataset/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "CIFAR10_test_set = torchvision.datasets.CIFAR10('/CIFAR10_dataset/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "# create a training and a validation set\n",
        "CIFAR10_training_set, CIFAR10_validation_set = random_split(CIFAR10_training, [45000, 5000])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(CIFAR10_training_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(CIFAR10_validation_set,batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(CIFAR10_test_set,batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /CIFAR10_dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 79042015.30it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /CIFAR10_dataset/cifar-10-python.tar.gz to /CIFAR10_dataset/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1MU6Yh56HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multiple Linear regression\n",
        "class MultipleLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultipleLinearRegression, self).__init__()\n",
        "        self.fc = nn.Linear(32*32*3, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTl6EgA_lwyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Following code appears at:  https://lirnli.wordpress.com/2017/09/03/one-hot-encoding-in-pytorch/\n",
        "class One_Hot(nn.Module):\n",
        "    def __init__(self, depth):\n",
        "        super(One_Hot,self).__init__()\n",
        "        self.depth = depth\n",
        "        self.ones = torch.sparse.torch.eye(depth).to(device)\n",
        "    def forward(self, X_in):\n",
        "        X_in = X_in.long()\n",
        "        return self.ones.index_select(0,X_in.data)\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"({})\".format(self.depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy8SKSrG6KxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(multi_linear_model, learning_rate=0.0001, momentum=0.5, epochs=2, optimizer_name=\"Adam\"):\n",
        "  multi_linear_model.train()\n",
        "  if optimizer_name == \"Adam\":\n",
        "      optimizer = optim.Adam(multi_linear_model.parameters(), lr=learning_rate)\n",
        "      \n",
        "  elif optimizer_name == \"SGD\":\n",
        "      optimizer = optim.SGD(multi_linear_model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    \n",
        "  for epoch in range(1, epochs + 1):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = multi_linear_model(data)\n",
        "      loss = F.mse_loss(output, one_hot(target)) # notice the use of view_as\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      error = loss.item();\n",
        "    print('EPOCH {} completed. learning_rate= {:.6f}, Training Loss: {:.4f}'.format( epoch,learning_rate,error))\n",
        "  return error\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr4Bd0BI6P7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(multi_linear_model):\n",
        "  multi_linear_model.eval()\n",
        "  validation_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # notice the use of no_grad\n",
        "    for data, target in validation_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = multi_linear_model(data)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "      validation_loss += F.mse_loss(output, one_hot(target), size_average=False).item()\n",
        "  validation_loss /= len(validation_loader.dataset)\n",
        "  print('Validation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(validation_loss, correct, len(validation_loader.dataset), 100. * correct / len(validation_loader.dataset)))\n",
        "  return 100. * correct / len(validation_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGcIxeFW0rR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(multi_linear_model):\n",
        "  multi_linear_model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = multi_linear_model(data)\n",
        "      test_loss += F.mse_loss(output, one_hot(target), size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hjjozQl6ARg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tune_hyper_parameter():\n",
        "  # -- Your code goes here --\n",
        "  lrs = [0.00004, 0.00006, 0.00008, 0.0001]\n",
        "  lrss = [0.00008, 0.0001, 0.0004, 0.0006]\n",
        "  mmts = [0.9, 0.7, 0.5, 0.3]\n",
        "  # Known issue: As one of the TA mentioned, epochs of 5 is not practicle for an accuracy of 38%, so we used 10 epochs instead.\n",
        "  epochs = 10\n",
        "  current_accuracy, max_accuracy, best_lr, best_mmt = 0, 0, 0, 0\n",
        "  optimizer = \"None\"\n",
        "\n",
        "  ## Perform your hyper-parameter search for Adam\n",
        "  print(\"Performing hyper-parameter grid search for Adam...\\n\")\n",
        "  for lr in lrs:\n",
        "    multi_linear_model = MultipleLinearRegression().to(device)\n",
        "    train(multi_linear_model, learning_rate=lr, epochs=epochs, optimizer_name=\"Adam\")\n",
        "    current_accuracy = validation(multi_linear_model)\n",
        "    if (current_accuracy > max_accuracy):\n",
        "      max_accuracy = current_accuracy\n",
        "      best_lr = lr\n",
        "      optimizer = \"Adam\"\n",
        "      print(\"Performing test...\\n\")\n",
        "      test(multi_linear_model)\n",
        "  \n",
        "  ## Perform your hyper-parameter search for SGD\n",
        "  print(\"Performing hyper-parameter grid search for SGD...\\n\")\n",
        "  for lr in lrss:\n",
        "    for mmt in mmts:\n",
        "      multi_linear_model = MultipleLinearRegression().to(device)\n",
        "      train(multi_linear_model, learning_rate=lr, momentum=mmt, epochs=epochs, optimizer_name=\"SGD\")\n",
        "      current_accuracy = validation(multi_linear_model)\n",
        "      if (current_accuracy > max_accuracy):\n",
        "        max_accuracy = current_accuracy\n",
        "        best_lr = lr\n",
        "        best_mmt = mmt\n",
        "        optimizer = \"SGD\"\n",
        "        print(\"Performing test...\\n\")\n",
        "        test(multi_linear_model)\n",
        "\n",
        "  ##Final output will be like:\n",
        "  \n",
        "  #Best performance: Validation Accuracy=38% , with Adam optimizer learning_rate=0.??????\n",
        "  \n",
        "  #or\n",
        "  \n",
        "  #Best performance: Validation Accuracy=37% , with SGD optimizer learning_rate=0.?????? and momentum=0.???\n",
        "  if optimizer == \"Adam\":\n",
        "    print(\"Best performance: Validation Accuracy={}% , with Adam optimizer learning_rate={:f}\\n\".format(max_accuracy.item(), best_lr))\n",
        "  elif optimizer == \"SGD\":\n",
        "    print(\"Best performance: Validation Accuracy={}% , with SGD optimizer learning_rate={:f} and momentum={:.3f}\\n\".format(max_accuracy.item(), best_lr, best_mmt))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRG7c7Sy6XOs",
        "colab_type": "code",
        "outputId": "77208458-21cf-45ac-8b5b-47ae831fe9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "##Final Block\n",
        "##Keep the output block of this section while submitting your solution \n",
        "##The last line of the output must contain the accuracy and best configuration information\n",
        "multi_linear_model = MultipleLinearRegression().to(device)\n",
        "one_hot = One_Hot(10).to(device)\n",
        "validation(multi_linear_model)\n",
        "tune_hyper_parameter()\n",
        "        \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation set: Avg. loss: 1.8523, Accuracy: 479/5000 (9%)\n",
            "\n",
            "Performing hyper-parameter grid search for Adam...\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000040, Training Loss: 0.0888\n",
            "EPOCH 2 completed. learning_rate= 0.000040, Training Loss: 0.0876\n",
            "EPOCH 3 completed. learning_rate= 0.000040, Training Loss: 0.0866\n",
            "EPOCH 4 completed. learning_rate= 0.000040, Training Loss: 0.0878\n",
            "EPOCH 5 completed. learning_rate= 0.000040, Training Loss: 0.0827\n",
            "EPOCH 6 completed. learning_rate= 0.000040, Training Loss: 0.0805\n",
            "EPOCH 7 completed. learning_rate= 0.000040, Training Loss: 0.0800\n",
            "EPOCH 8 completed. learning_rate= 0.000040, Training Loss: 0.0765\n",
            "EPOCH 9 completed. learning_rate= 0.000040, Training Loss: 0.0811\n",
            "EPOCH 10 completed. learning_rate= 0.000040, Training Loss: 0.0766\n",
            "Validation set: Avg. loss: 0.8095, Accuracy: 1862/5000 (37%)\n",
            "\n",
            "Performing test...\n",
            "\n",
            "Test set: Avg. loss: 0.8095, Accuracy: 3730/10000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000060, Training Loss: 0.0887\n",
            "EPOCH 2 completed. learning_rate= 0.000060, Training Loss: 0.0899\n",
            "EPOCH 3 completed. learning_rate= 0.000060, Training Loss: 0.0832\n",
            "EPOCH 4 completed. learning_rate= 0.000060, Training Loss: 0.0802\n",
            "EPOCH 5 completed. learning_rate= 0.000060, Training Loss: 0.0826\n",
            "EPOCH 6 completed. learning_rate= 0.000060, Training Loss: 0.0713\n",
            "EPOCH 7 completed. learning_rate= 0.000060, Training Loss: 0.0759\n",
            "EPOCH 8 completed. learning_rate= 0.000060, Training Loss: 0.0821\n",
            "EPOCH 9 completed. learning_rate= 0.000060, Training Loss: 0.0796\n",
            "EPOCH 10 completed. learning_rate= 0.000060, Training Loss: 0.0769\n",
            "Validation set: Avg. loss: 0.8094, Accuracy: 1853/5000 (37%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000080, Training Loss: 0.0891\n",
            "EPOCH 2 completed. learning_rate= 0.000080, Training Loss: 0.0858\n",
            "EPOCH 3 completed. learning_rate= 0.000080, Training Loss: 0.0828\n",
            "EPOCH 4 completed. learning_rate= 0.000080, Training Loss: 0.0781\n",
            "EPOCH 5 completed. learning_rate= 0.000080, Training Loss: 0.0800\n",
            "EPOCH 6 completed. learning_rate= 0.000080, Training Loss: 0.0783\n",
            "EPOCH 7 completed. learning_rate= 0.000080, Training Loss: 0.0763\n",
            "EPOCH 8 completed. learning_rate= 0.000080, Training Loss: 0.0812\n",
            "EPOCH 9 completed. learning_rate= 0.000080, Training Loss: 0.0722\n",
            "EPOCH 10 completed. learning_rate= 0.000080, Training Loss: 0.0805\n",
            "Validation set: Avg. loss: 0.8060, Accuracy: 1904/5000 (38%)\n",
            "\n",
            "Performing test...\n",
            "\n",
            "Test set: Avg. loss: 0.8053, Accuracy: 3823/10000 (38%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000100, Training Loss: 0.0885\n",
            "EPOCH 2 completed. learning_rate= 0.000100, Training Loss: 0.0809\n",
            "EPOCH 3 completed. learning_rate= 0.000100, Training Loss: 0.0809\n",
            "EPOCH 4 completed. learning_rate= 0.000100, Training Loss: 0.0841\n",
            "EPOCH 5 completed. learning_rate= 0.000100, Training Loss: 0.0763\n",
            "EPOCH 6 completed. learning_rate= 0.000100, Training Loss: 0.0797\n",
            "EPOCH 7 completed. learning_rate= 0.000100, Training Loss: 0.0777\n",
            "EPOCH 8 completed. learning_rate= 0.000100, Training Loss: 0.0880\n",
            "EPOCH 9 completed. learning_rate= 0.000100, Training Loss: 0.0835\n",
            "EPOCH 10 completed. learning_rate= 0.000100, Training Loss: 0.0790\n",
            "Validation set: Avg. loss: 0.8152, Accuracy: 1809/5000 (36%)\n",
            "\n",
            "Performing hyper-parameter grid search for SGD...\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000080, Training Loss: 0.1101\n",
            "EPOCH 2 completed. learning_rate= 0.000080, Training Loss: 0.1043\n",
            "EPOCH 3 completed. learning_rate= 0.000080, Training Loss: 0.0975\n",
            "EPOCH 4 completed. learning_rate= 0.000080, Training Loss: 0.1025\n",
            "EPOCH 5 completed. learning_rate= 0.000080, Training Loss: 0.0960\n",
            "EPOCH 6 completed. learning_rate= 0.000080, Training Loss: 0.0954\n",
            "EPOCH 7 completed. learning_rate= 0.000080, Training Loss: 0.0939\n",
            "EPOCH 8 completed. learning_rate= 0.000080, Training Loss: 0.0981\n",
            "EPOCH 9 completed. learning_rate= 0.000080, Training Loss: 0.0978\n",
            "EPOCH 10 completed. learning_rate= 0.000080, Training Loss: 0.0897\n",
            "Validation set: Avg. loss: 0.9153, Accuracy: 1440/5000 (28%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000080, Training Loss: 0.1234\n",
            "EPOCH 2 completed. learning_rate= 0.000080, Training Loss: 0.1193\n",
            "EPOCH 3 completed. learning_rate= 0.000080, Training Loss: 0.1060\n",
            "EPOCH 4 completed. learning_rate= 0.000080, Training Loss: 0.1064\n",
            "EPOCH 5 completed. learning_rate= 0.000080, Training Loss: 0.1079\n",
            "EPOCH 6 completed. learning_rate= 0.000080, Training Loss: 0.1088\n",
            "EPOCH 7 completed. learning_rate= 0.000080, Training Loss: 0.1031\n",
            "EPOCH 8 completed. learning_rate= 0.000080, Training Loss: 0.0992\n",
            "EPOCH 9 completed. learning_rate= 0.000080, Training Loss: 0.1005\n",
            "EPOCH 10 completed. learning_rate= 0.000080, Training Loss: 0.1007\n",
            "Validation set: Avg. loss: 1.0159, Accuracy: 1086/5000 (21%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000080, Training Loss: 0.1456\n",
            "EPOCH 2 completed. learning_rate= 0.000080, Training Loss: 0.1249\n",
            "EPOCH 3 completed. learning_rate= 0.000080, Training Loss: 0.1124\n",
            "EPOCH 4 completed. learning_rate= 0.000080, Training Loss: 0.1128\n",
            "EPOCH 5 completed. learning_rate= 0.000080, Training Loss: 0.1071\n",
            "EPOCH 6 completed. learning_rate= 0.000080, Training Loss: 0.1205\n",
            "EPOCH 7 completed. learning_rate= 0.000080, Training Loss: 0.1084\n",
            "EPOCH 8 completed. learning_rate= 0.000080, Training Loss: 0.1008\n",
            "EPOCH 9 completed. learning_rate= 0.000080, Training Loss: 0.1133\n",
            "EPOCH 10 completed. learning_rate= 0.000080, Training Loss: 0.1025\n",
            "Validation set: Avg. loss: 1.0507, Accuracy: 1047/5000 (20%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000080, Training Loss: 0.1385\n",
            "EPOCH 2 completed. learning_rate= 0.000080, Training Loss: 0.1444\n",
            "EPOCH 3 completed. learning_rate= 0.000080, Training Loss: 0.1240\n",
            "EPOCH 4 completed. learning_rate= 0.000080, Training Loss: 0.1217\n",
            "EPOCH 5 completed. learning_rate= 0.000080, Training Loss: 0.1171\n",
            "EPOCH 6 completed. learning_rate= 0.000080, Training Loss: 0.1057\n",
            "EPOCH 7 completed. learning_rate= 0.000080, Training Loss: 0.1105\n",
            "EPOCH 8 completed. learning_rate= 0.000080, Training Loss: 0.1113\n",
            "EPOCH 9 completed. learning_rate= 0.000080, Training Loss: 0.1109\n",
            "EPOCH 10 completed. learning_rate= 0.000080, Training Loss: 0.1114\n",
            "Validation set: Avg. loss: 1.0917, Accuracy: 938/5000 (18%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000100, Training Loss: 0.1125\n",
            "EPOCH 2 completed. learning_rate= 0.000100, Training Loss: 0.1005\n",
            "EPOCH 3 completed. learning_rate= 0.000100, Training Loss: 0.1019\n",
            "EPOCH 4 completed. learning_rate= 0.000100, Training Loss: 0.0934\n",
            "EPOCH 5 completed. learning_rate= 0.000100, Training Loss: 0.0885\n",
            "EPOCH 6 completed. learning_rate= 0.000100, Training Loss: 0.0944\n",
            "EPOCH 7 completed. learning_rate= 0.000100, Training Loss: 0.0891\n",
            "EPOCH 8 completed. learning_rate= 0.000100, Training Loss: 0.0913\n",
            "EPOCH 9 completed. learning_rate= 0.000100, Training Loss: 0.0901\n",
            "EPOCH 10 completed. learning_rate= 0.000100, Training Loss: 0.0852\n",
            "Validation set: Avg. loss: 0.9009, Accuracy: 1431/5000 (28%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000100, Training Loss: 0.1328\n",
            "EPOCH 2 completed. learning_rate= 0.000100, Training Loss: 0.1176\n",
            "EPOCH 3 completed. learning_rate= 0.000100, Training Loss: 0.1102\n",
            "EPOCH 4 completed. learning_rate= 0.000100, Training Loss: 0.1036\n",
            "EPOCH 5 completed. learning_rate= 0.000100, Training Loss: 0.1026\n",
            "EPOCH 6 completed. learning_rate= 0.000100, Training Loss: 0.1001\n",
            "EPOCH 7 completed. learning_rate= 0.000100, Training Loss: 0.1055\n",
            "EPOCH 8 completed. learning_rate= 0.000100, Training Loss: 0.0967\n",
            "EPOCH 9 completed. learning_rate= 0.000100, Training Loss: 0.1016\n",
            "EPOCH 10 completed. learning_rate= 0.000100, Training Loss: 0.0975\n",
            "Validation set: Avg. loss: 0.9865, Accuracy: 1190/5000 (23%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000100, Training Loss: 0.1345\n",
            "EPOCH 2 completed. learning_rate= 0.000100, Training Loss: 0.1176\n",
            "EPOCH 3 completed. learning_rate= 0.000100, Training Loss: 0.1205\n",
            "EPOCH 4 completed. learning_rate= 0.000100, Training Loss: 0.1117\n",
            "EPOCH 5 completed. learning_rate= 0.000100, Training Loss: 0.1084\n",
            "EPOCH 6 completed. learning_rate= 0.000100, Training Loss: 0.1056\n",
            "EPOCH 7 completed. learning_rate= 0.000100, Training Loss: 0.1071\n",
            "EPOCH 8 completed. learning_rate= 0.000100, Training Loss: 0.1057\n",
            "EPOCH 9 completed. learning_rate= 0.000100, Training Loss: 0.0949\n",
            "EPOCH 10 completed. learning_rate= 0.000100, Training Loss: 0.1011\n",
            "Validation set: Avg. loss: 1.0301, Accuracy: 1101/5000 (22%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000100, Training Loss: 0.1382\n",
            "EPOCH 2 completed. learning_rate= 0.000100, Training Loss: 0.1232\n",
            "EPOCH 3 completed. learning_rate= 0.000100, Training Loss: 0.1124\n",
            "EPOCH 4 completed. learning_rate= 0.000100, Training Loss: 0.1136\n",
            "EPOCH 5 completed. learning_rate= 0.000100, Training Loss: 0.1241\n",
            "EPOCH 6 completed. learning_rate= 0.000100, Training Loss: 0.1120\n",
            "EPOCH 7 completed. learning_rate= 0.000100, Training Loss: 0.1065\n",
            "EPOCH 8 completed. learning_rate= 0.000100, Training Loss: 0.1096\n",
            "EPOCH 9 completed. learning_rate= 0.000100, Training Loss: 0.1005\n",
            "EPOCH 10 completed. learning_rate= 0.000100, Training Loss: 0.1058\n",
            "Validation set: Avg. loss: 1.0625, Accuracy: 985/5000 (19%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000400, Training Loss: 0.0974\n",
            "EPOCH 2 completed. learning_rate= 0.000400, Training Loss: 0.0902\n",
            "EPOCH 3 completed. learning_rate= 0.000400, Training Loss: 0.0883\n",
            "EPOCH 4 completed. learning_rate= 0.000400, Training Loss: 0.0853\n",
            "EPOCH 5 completed. learning_rate= 0.000400, Training Loss: 0.0853\n",
            "EPOCH 6 completed. learning_rate= 0.000400, Training Loss: 0.0862\n",
            "EPOCH 7 completed. learning_rate= 0.000400, Training Loss: 0.0865\n",
            "EPOCH 8 completed. learning_rate= 0.000400, Training Loss: 0.0819\n",
            "EPOCH 9 completed. learning_rate= 0.000400, Training Loss: 0.0866\n",
            "EPOCH 10 completed. learning_rate= 0.000400, Training Loss: 0.0821\n",
            "Validation set: Avg. loss: 0.8259, Accuracy: 1751/5000 (35%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000400, Training Loss: 0.1086\n",
            "EPOCH 2 completed. learning_rate= 0.000400, Training Loss: 0.0984\n",
            "EPOCH 3 completed. learning_rate= 0.000400, Training Loss: 0.0979\n",
            "EPOCH 4 completed. learning_rate= 0.000400, Training Loss: 0.0872\n",
            "EPOCH 5 completed. learning_rate= 0.000400, Training Loss: 0.0925\n",
            "EPOCH 6 completed. learning_rate= 0.000400, Training Loss: 0.0924\n",
            "EPOCH 7 completed. learning_rate= 0.000400, Training Loss: 0.0903\n",
            "EPOCH 8 completed. learning_rate= 0.000400, Training Loss: 0.0887\n",
            "EPOCH 9 completed. learning_rate= 0.000400, Training Loss: 0.0877\n",
            "EPOCH 10 completed. learning_rate= 0.000400, Training Loss: 0.0914\n",
            "Validation set: Avg. loss: 0.8815, Accuracy: 1577/5000 (31%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000400, Training Loss: 0.1157\n",
            "EPOCH 2 completed. learning_rate= 0.000400, Training Loss: 0.1150\n",
            "EPOCH 3 completed. learning_rate= 0.000400, Training Loss: 0.1059\n",
            "EPOCH 4 completed. learning_rate= 0.000400, Training Loss: 0.1029\n",
            "EPOCH 5 completed. learning_rate= 0.000400, Training Loss: 0.0988\n",
            "EPOCH 6 completed. learning_rate= 0.000400, Training Loss: 0.0946\n",
            "EPOCH 7 completed. learning_rate= 0.000400, Training Loss: 0.0965\n",
            "EPOCH 8 completed. learning_rate= 0.000400, Training Loss: 0.0876\n",
            "EPOCH 9 completed. learning_rate= 0.000400, Training Loss: 0.0865\n",
            "EPOCH 10 completed. learning_rate= 0.000400, Training Loss: 0.0928\n",
            "Validation set: Avg. loss: 0.9182, Accuracy: 1430/5000 (28%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000400, Training Loss: 0.1250\n",
            "EPOCH 2 completed. learning_rate= 0.000400, Training Loss: 0.1017\n",
            "EPOCH 3 completed. learning_rate= 0.000400, Training Loss: 0.1005\n",
            "EPOCH 4 completed. learning_rate= 0.000400, Training Loss: 0.1031\n",
            "EPOCH 5 completed. learning_rate= 0.000400, Training Loss: 0.0973\n",
            "EPOCH 6 completed. learning_rate= 0.000400, Training Loss: 0.0980\n",
            "EPOCH 7 completed. learning_rate= 0.000400, Training Loss: 0.0957\n",
            "EPOCH 8 completed. learning_rate= 0.000400, Training Loss: 0.0961\n",
            "EPOCH 9 completed. learning_rate= 0.000400, Training Loss: 0.0913\n",
            "EPOCH 10 completed. learning_rate= 0.000400, Training Loss: 0.0917\n",
            "Validation set: Avg. loss: 0.9343, Accuracy: 1357/5000 (27%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000600, Training Loss: 0.0918\n",
            "EPOCH 2 completed. learning_rate= 0.000600, Training Loss: 0.0870\n",
            "EPOCH 3 completed. learning_rate= 0.000600, Training Loss: 0.0804\n",
            "EPOCH 4 completed. learning_rate= 0.000600, Training Loss: 0.0812\n",
            "EPOCH 5 completed. learning_rate= 0.000600, Training Loss: 0.0862\n",
            "EPOCH 6 completed. learning_rate= 0.000600, Training Loss: 0.0827\n",
            "EPOCH 7 completed. learning_rate= 0.000600, Training Loss: 0.0817\n",
            "EPOCH 8 completed. learning_rate= 0.000600, Training Loss: 0.0787\n",
            "EPOCH 9 completed. learning_rate= 0.000600, Training Loss: 0.0737\n",
            "EPOCH 10 completed. learning_rate= 0.000600, Training Loss: 0.0819\n",
            "Validation set: Avg. loss: 0.8180, Accuracy: 1775/5000 (35%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000600, Training Loss: 0.1019\n",
            "EPOCH 2 completed. learning_rate= 0.000600, Training Loss: 0.0968\n",
            "EPOCH 3 completed. learning_rate= 0.000600, Training Loss: 0.0995\n",
            "EPOCH 4 completed. learning_rate= 0.000600, Training Loss: 0.0893\n",
            "EPOCH 5 completed. learning_rate= 0.000600, Training Loss: 0.0895\n",
            "EPOCH 6 completed. learning_rate= 0.000600, Training Loss: 0.0865\n",
            "EPOCH 7 completed. learning_rate= 0.000600, Training Loss: 0.0864\n",
            "EPOCH 8 completed. learning_rate= 0.000600, Training Loss: 0.0864\n",
            "EPOCH 9 completed. learning_rate= 0.000600, Training Loss: 0.0885\n",
            "EPOCH 10 completed. learning_rate= 0.000600, Training Loss: 0.0812\n",
            "Validation set: Avg. loss: 0.8571, Accuracy: 1602/5000 (32%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000600, Training Loss: 0.1080\n",
            "EPOCH 2 completed. learning_rate= 0.000600, Training Loss: 0.0986\n",
            "EPOCH 3 completed. learning_rate= 0.000600, Training Loss: 0.0993\n",
            "EPOCH 4 completed. learning_rate= 0.000600, Training Loss: 0.0891\n",
            "EPOCH 5 completed. learning_rate= 0.000600, Training Loss: 0.0894\n",
            "EPOCH 6 completed. learning_rate= 0.000600, Training Loss: 0.0989\n",
            "EPOCH 7 completed. learning_rate= 0.000600, Training Loss: 0.0919\n",
            "EPOCH 8 completed. learning_rate= 0.000600, Training Loss: 0.0934\n",
            "EPOCH 9 completed. learning_rate= 0.000600, Training Loss: 0.0895\n",
            "EPOCH 10 completed. learning_rate= 0.000600, Training Loss: 0.0874\n",
            "Validation set: Avg. loss: 0.8923, Accuracy: 1505/5000 (30%)\n",
            "\n",
            "EPOCH 1 completed. learning_rate= 0.000600, Training Loss: 0.1102\n",
            "EPOCH 2 completed. learning_rate= 0.000600, Training Loss: 0.1055\n",
            "EPOCH 3 completed. learning_rate= 0.000600, Training Loss: 0.0998\n",
            "EPOCH 4 completed. learning_rate= 0.000600, Training Loss: 0.1020\n",
            "EPOCH 5 completed. learning_rate= 0.000600, Training Loss: 0.0931\n",
            "EPOCH 6 completed. learning_rate= 0.000600, Training Loss: 0.0949\n",
            "EPOCH 7 completed. learning_rate= 0.000600, Training Loss: 0.0911\n",
            "EPOCH 8 completed. learning_rate= 0.000600, Training Loss: 0.0872\n",
            "EPOCH 9 completed. learning_rate= 0.000600, Training Loss: 0.0918\n",
            "EPOCH 10 completed. learning_rate= 0.000600, Training Loss: 0.0900\n",
            "Validation set: Avg. loss: 0.9101, Accuracy: 1430/5000 (28%)\n",
            "\n",
            "Best performance: Validation Accuracy=38% , with Adam optimizer learning_rate=0.000080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}