{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_8_1370023.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EHD1DOQVACzP","colab_type":"code","outputId":"e2c94d1c-85f2-4cc5-eff4-b818cf2deac5","executionInfo":{"status":"ok","timestamp":1573335119234,"user_tz":420,"elapsed":21789,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["import os\n","import time\n","\n","import torch.nn.functional as F\n","import torch\n","from torch import nn\n","from torchvision import models\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#Edit root_dir here to point where the TextureImagesDataset folder \n","root_dir = '/content/drive/My Drive/Colab Notebooks/A8'\n","\n","class TextureImages(object):\n","    def __init__(self, subset='train', batch_size=64, shuffle=True):\n","        if subset == 'train':\n","            images = np.load(os.path.join(root_dir, 'TextureImagesDataset',\n","                                          'train_images.npy'))\n","            masks = np.load(os.path.join(root_dir, 'TextureImagesDataset',\n","                                         'train_masks.npy'))\n","        elif subset == 'test':\n","            images = np.load(os.path.join(root_dir, 'TextureImagesDataset',\n","                                          'test_images.npy'))\n","            masks = np.load(os.path.join(root_dir, 'TextureImagesDataset',\n","                                         'test_masks.npy'))\n","        else:\n","            raise NotImplementedError\n","        self._images = images\n","        self.images = self._images\n","        self._masks = masks\n","        self.masks = self._masks\n","        self.batch_size = batch_size\n","        self.num_samples = len(self.images)\n","        self.shuffle = shuffle\n","        if self.shuffle:\n","            self.shuffle_samples()\n","        self.next_batch_pointer = 0\n","\n","    def shuffle_samples(self):\n","        image_indices = np.random.permutation(np.arange(self.num_samples))\n","        self.images = self._images[image_indices]\n","        self.masks = self._masks[image_indices]\n","\n","    def get_next_batch(self):\n","        num_samples_left = self.num_samples - self.next_batch_pointer\n","        if num_samples_left >= self.batch_size:\n","            x_batch = self.images[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n","            y_batch = self.masks[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n","            self.next_batch_pointer += self.batch_size\n","        else:\n","            x_partial_batch_1 = self.images[self.next_batch_pointer:self.num_samples]\n","            y_partial_batch_1 = self.masks[self.next_batch_pointer:self.num_samples]\n","            if self.shuffle:\n","                self.shuffle_samples()\n","            x_partial_batch_2 = self.images[0:self.batch_size - num_samples_left]\n","            y_partial_batch_2 = self.masks[0:self.batch_size - num_samples_left]\n","            x_batch = np.vstack((x_partial_batch_1, x_partial_batch_2))\n","            y_batch = np.vstack((y_partial_batch_1, y_partial_batch_2))\n","            self.next_batch_pointer = self.batch_size - num_samples_left\n","        return x_batch, y_batch\n","\n","class CrossEntropyLoss2d(nn.Module):\n","    def __init__(self, weight=None, size_average=True, ignore_index=255):\n","        super(CrossEntropyLoss2d, self).__init__()\n","        self.nll_loss = nn.NLLLoss(weight, size_average, ignore_index)\n","\n","    def forward(self, inputs, targets):\n","        return self.nll_loss(F.log_softmax(inputs, dim=1), targets)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RSyJsklzzojQ","colab_type":"code","colab":{}},"source":["class SemSeg(nn.Module):\n","    # TODO: Implement Semantic Segmentation network here\n","    # Returned logits must be a tensor of size:\n","    # (<batch_size>, image_height, image_width, num_classes + 1)\n","    # 1st dimension is batch dimension\n","    # image_height and image_width are the height and width of input_tensor\n","    # last dimension is the softmax dimension. There are 4 texture classes plus 1 background class\n","    # therefore last dimension will be 5\n","    def __init__(self):\n","      super(SemSeg, self).__init__()\n","      # encoder convolutional layers\n","      self.encoder1 = nn.Conv2d(3, 12, kernel_size=5)\n","      self.encoder2 = nn.Conv2d(12, 36, kernel_size=5)\n","      self.encoder3 = nn.Conv2d(36, 52, kernel_size=5)\n","\n","      # decoder convolutional layers\n","      self.decoder1 = nn.ConvTranspose2d(in_channels=52, out_channels=36, kernel_size=5, stride=2,output_padding=1)\n","      self.decoder2 = nn.ConvTranspose2d(in_channels=36, out_channels=12, kernel_size=5, stride=2,output_padding=1)\n","      self.output = nn.ConvTranspose2d(in_channels=12, out_channels=5, kernel_size=5, stride=2,output_padding=1)\n","\n","      # Xavier initialization\n","      torch.nn.init.xavier_normal_(self.encoder1.weight)\n","      torch.nn.init.xavier_normal_(self.encoder2.weight)\n","      torch.nn.init.xavier_normal_(self.encoder3.weight)\n","      torch.nn.init.xavier_normal_(self.decoder1.weight)\n","      torch.nn.init.xavier_normal_(self.decoder2.weight)\n","      torch.nn.init.xavier_normal_(self.output.weight)\n","\n","    def forward(self, x):\n","      x = F.relu(self.encoder1(x))\n","      x1 = F.max_pool2d(x, kernel_size=2, stride=2)\n","      x2 = F.relu(self.encoder2(x1))\n","      x3 = F.max_pool2d(x2, kernel_size=2, stride=2)\n","      x4 = F.relu(self.encoder3(x3))\n","      x5 = F.max_pool2d(x4, kernel_size=2, stride=2)\n","      x6 = F.relu(self.decoder1(x5))\n","      x7 = F.relu(self.decoder2(x6))\n","      x8 = self.output(x7)\n","      return F.log_softmax(x8, dim=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0wpkK7d9zWJ","colab_type":"code","outputId":"b76d365f-ec5d-4807-c35c-4e3dba2ccfcf","executionInfo":{"status":"ok","timestamp":1573335475184,"user_tz":420,"elapsed":377726,"user":{"displayName":"Ziming Fu","photoUrl":"","userId":"13730860658836574087"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["def run():\n","    # You can tune the hyperparameters here.\n","    n_epochs = 25\n","    batch_size = 16\n","    learning_rate = 0.001\n","    weight_decay = 0.001\n","    use_cuda = 1\n","\n","    load_weights = 0\n","    wts_fname = 'model.pt'\n","\n","    input_size = (196, 196)\n","    n_batches = int(2000 / batch_size)\n","    wts_path = os.path.join(root_dir, wts_fname)\n","\n","    if use_cuda and torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","        print('Training on GPU: {}'.format(torch.cuda.get_device_name(0)))\n","    else:\n","        device = torch.device(\"cpu\")\n","        print('Training on CPU')\n","\n","    train_set = TextureImages('train', batch_size=batch_size)\n","    test_set = TextureImages('test', shuffle=False)\n","\n","    model = SemSeg().to(device)\n","\n","    def evaluation(images, true_labels):\n","        eval_batch_size = 100\n","        predicted_labels = []\n","        model.eval()\n","        with torch.no_grad():\n","            for start_index in range(0, len(images), eval_batch_size):\n","                end_index = start_index + eval_batch_size\n","                batch_x = images[start_index: end_index]\n","                # batch_x = np.reshape(batch_x, (batch_x.shape[0], 3, 196, 196))\n","                batch_x = torch.FloatTensor(batch_x).permute((0, 3, 1, 2)).to(device)\n","                batch_predicted_logits = model(batch_x)\n","                batch_predicted_labels = torch.argmax(batch_predicted_logits, axis=1)\n","                batch_predicted_labels = batch_predicted_labels.cpu().numpy()\n","                predicted_labels += list(batch_predicted_labels)\n","        predicted_labels = np.vstack(predicted_labels).flatten()\n","        true_labels = true_labels.flatten()\n","        accuracy = float((predicted_labels == true_labels).astype(np.int32).sum()) / true_labels.size\n","        return predicted_labels, accuracy\n","\n","    if load_weights:      \n","        print('Loading weights from: {}'.format(wts_path))\n","        chkpt = torch.load(wts_path, map_location=device)  # load checkpoint\n","        model.load_state_dict(chkpt['model'])\n","    else:\n","        criterion = CrossEntropyLoss2d().to(device)\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","        print(\"Training...\")\n","        mean_loss = 0\n","        steps = 0\n","        losses = []\n","        max_accuracy = 0\n","        max_accuracy_id = 0\n","        for epch_id in range(n_epochs):\n","            model.train()\n","            for batch_id in range(n_batches):\n","                start_t = time.time()\n","\n","                batch_x, batch_y = train_set.get_next_batch()\n","\n","                batch_x = torch.FloatTensor(batch_x).permute((0, 3, 1, 2)).to(device)\n","                batch_y = torch.LongTensor(batch_y).squeeze().to(device)\n","\n","                optimizer.zero_grad()\n","\n","                outputs = model(batch_x)\n","                loss = criterion(outputs, batch_y)\n","                loss.backward()\n","                optimizer.step()\n","\n","                end_t = time.time()\n","\n","                _loss = loss.item()\n","                steps += 1\n","                mean_loss += (_loss - mean_loss) / steps\n","                losses.append(_loss)\n","\n","                time_taken = end_t - start_t\n","\n","                #print('batch: {} / {} loss: {} mean_loss: {} time_taken: {}'.format(\n","                #    batch_id, n_batches, _loss, mean_loss, time_taken))\n","\n","            _, test_accuracy = evaluation(test_set._images, test_set._masks)\n","            if test_accuracy > max_accuracy:\n","                max_accuracy = test_accuracy\n","                max_accuracy_id = epch_id\n","                chkpt = {\n","                    'model': model.state_dict(),\n","                }\n","                torch.save(chkpt, '{}.{}'.format(wts_path, max_accuracy_id))\n","            print(\"epch {} / {}: Test Pixel Accuracy = {:.3f} max_accuracy = {:.3f} in epoch {}\".format(\n","                epch_id + 1, n_epochs, test_accuracy, max_accuracy, max_accuracy_id + 1))\n","        print(\"Done training. Weights saved to: {}\".format(wts_fname))\n","        chkpt = {\n","            'model': model.state_dict(),\n","        }\n","        torch.save(chkpt, wts_path)\n","\n","    print('Evaluating on test set')\n","    _, test_accuracy = evaluation(test_set._images, test_set._masks)\n","    print(\"Test Pixel Accuracy = {:.3f}\".format(test_accuracy))\n","    return test_accuracy\n","\n","\n","if __name__ == '__main__':\n","    run()\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training on GPU: Tesla K80\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["Training...\n","epch 1 / 25: Test Pixel Accuracy = 0.753 max_accuracy = 0.753 in epoch 1\n","epch 2 / 25: Test Pixel Accuracy = 0.942 max_accuracy = 0.942 in epoch 2\n","epch 3 / 25: Test Pixel Accuracy = 0.975 max_accuracy = 0.975 in epoch 3\n","epch 4 / 25: Test Pixel Accuracy = 0.980 max_accuracy = 0.980 in epoch 4\n","epch 5 / 25: Test Pixel Accuracy = 0.983 max_accuracy = 0.983 in epoch 5\n","epch 6 / 25: Test Pixel Accuracy = 0.985 max_accuracy = 0.985 in epoch 6\n","epch 7 / 25: Test Pixel Accuracy = 0.984 max_accuracy = 0.985 in epoch 6\n","epch 8 / 25: Test Pixel Accuracy = 0.986 max_accuracy = 0.986 in epoch 8\n","epch 9 / 25: Test Pixel Accuracy = 0.987 max_accuracy = 0.987 in epoch 9\n","epch 10 / 25: Test Pixel Accuracy = 0.987 max_accuracy = 0.987 in epoch 10\n","epch 11 / 25: Test Pixel Accuracy = 0.988 max_accuracy = 0.988 in epoch 11\n","epch 12 / 25: Test Pixel Accuracy = 0.987 max_accuracy = 0.988 in epoch 11\n","epch 13 / 25: Test Pixel Accuracy = 0.988 max_accuracy = 0.988 in epoch 13\n","epch 14 / 25: Test Pixel Accuracy = 0.988 max_accuracy = 0.988 in epoch 14\n","epch 15 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.989 in epoch 15\n","epch 16 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.989 in epoch 15\n","epch 17 / 25: Test Pixel Accuracy = 0.988 max_accuracy = 0.989 in epoch 15\n","epch 18 / 25: Test Pixel Accuracy = 0.990 max_accuracy = 0.990 in epoch 18\n","epch 19 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.990 in epoch 18\n","epch 20 / 25: Test Pixel Accuracy = 0.990 max_accuracy = 0.990 in epoch 18\n","epch 21 / 25: Test Pixel Accuracy = 0.990 max_accuracy = 0.990 in epoch 21\n","epch 22 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.990 in epoch 21\n","epch 23 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.990 in epoch 21\n","epch 24 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.990 in epoch 21\n","epch 25 / 25: Test Pixel Accuracy = 0.990 max_accuracy = 0.990 in epoch 21\n","Done training. Weights saved to: model.pt\n","Evaluating on test set\n","Test Pixel Accuracy = 0.990\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IBaXJdvg_ZXV","colab_type":"text"},"source":["#Possible Output \n","Training on GPU: Tesla K80\n","\n","Training...\n","\n","epch 1 / 25: Test Pixel Accuracy = 0.865 max_accuracy = 0.865 in epoch 1\n","\n","epch 2 / 25: Test Pixel Accuracy = 0.945 max_accuracy = 0.945 in epoch 2\n","\n","epch 3 / 25: Test Pixel Accuracy = 0.938 max_accuracy = 0.945 in epoch 2\n","\n","epch 4 / 25: Test Pixel Accuracy = 0.975 max_accuracy = 0.975 in epoch 4\n","\n","epch 5 / 25: Test Pixel Accuracy = 0.981 max_accuracy = 0.981 in epoch 5\n","\n","epch 6 / 25: Test Pixel Accuracy = 0.982 max_accuracy = 0.982 in epoch 6\n","\n","epch 7 / 25: Test Pixel Accuracy = 0.583 max_accuracy = 0.982 in epoch 6\n","\n","epch 8 / 25: Test Pixel Accuracy = 0.959 max_accuracy = 0.982 in epoch 6\n","\n","epch 9 / 25: Test Pixel Accuracy = 0.762 max_accuracy = 0.982 in epoch 6\n","\n","epch 10 / 25: Test Pixel Accuracy = 0.864 max_accuracy = 0.982 in epoch 6\n","\n","epch 11 / 25: Test Pixel Accuracy = 0.941 max_accuracy = 0.982 in epoch 6\n","\n","epch 12 / 25: Test Pixel Accuracy = 0.963 max_accuracy = 0.982 in epoch 6\n","\n","epch 13 / 25: Test Pixel Accuracy = 0.954 max_accuracy = 0.982 in epoch 6\n","\n","epch 14 / 25: Test Pixel Accuracy = 0.821 max_accuracy = 0.982 in epoch 6\n","\n","epch 15 / 25: Test Pixel Accuracy = 0.846 max_accuracy = 0.982 in epoch 6\n","\n","epch 16 / 25: Test Pixel Accuracy = 0.967 max_accuracy = 0.982 in epoch 6\n","\n","epch 17 / 25: Test Pixel Accuracy = 0.945 max_accuracy = 0.982 in epoch 6\n","\n","epch 18 / 25: Test Pixel Accuracy = 0.971 max_accuracy = 0.982 in epoch 6\n","\n","epch 19 / 25: Test Pixel Accuracy = 0.985 max_accuracy = 0.985 in epoch 19\n","\n","epch 20 / 25: Test Pixel Accuracy = 0.980 max_accuracy = 0.985 in epoch 19\n","\n","epch 21 / 25: Test Pixel Accuracy = 0.986 max_accuracy = 0.986 in epoch 21\n","\n","epch 22 / 25: Test Pixel Accuracy = 0.988 max_accuracy = 0.988 in epoch 22\n","\n","epch 23 / 25: Test Pixel Accuracy = 0.989 max_accuracy = 0.989 in epoch 23\n","\n","epch 24 / 25: Test Pixel Accuracy = 0.982 max_accuracy = 0.989 in epoch 23\n","\n","epch 25 / 25: Test Pixel Accuracy = 0.987 max_accuracy = 0.989 in epoch 23\n","\n","Done training. Weights saved to: model.pt\n","\n","Evaluating on test set\n","\n","Test Pixel Accuracy = 0.987"]}]}