# -*- coding: utf-8 -*-
"""Assignment_5_pytorch_notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OSqFeef6rIUIQmld4uARsrOZMVyIXEsY

Import and setup some auxiliary functions
"""

# Don't edit this cell
import torch
from torchvision import transforms, datasets
import numpy as np
import timeit
from collections import OrderedDict
from pprint import pformat
from torch.utils.data.sampler import *
from tqdm import tqdm
import time
from google.colab import drive

import torch.nn as nn
import torch.nn.functional as F

torch.multiprocessing.set_sharing_strategy('file_system')

def compute_score(acc, min_thres, max_thres):
    if acc <= min_thres:
        base_score = 0.0
    elif acc >= max_thres:
        base_score = 100.0
    else:
        base_score = float(acc - min_thres) / (max_thres - min_thres) \
                     * 100
    return base_score


def run(algorithm, dataset_name, filename):
    predicted_test_labels, gt_labels, run_time = algorithm(dataset_name)
    if predicted_test_labels is None or gt_labels is None:
      return (0, 0, 0)

    correct = 0
    total = 0
    for label, prediction in zip(gt_labels, predicted_test_labels):
      total += label.size(0)
      correct += (prediction.cpu().numpy() == label.cpu().numpy()).sum().item()   # assuming your model runs on GPU
      
    accuracy = float(correct) / total
    
    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))
    return (correct, accuracy, run_time)

"""Your implementation starts here"""

# Part[1] TODO: Cifar-10 dataloading
def load_data(dataset_name, device, config):
    """
    loads cifar-10 dataset using torchvision, take the last 5k of the training data to be validation data
    """
    # Import batch_size and transforms from config
    batch_size = config['batch_size']
    transform = config['transforms']
      
    # Setup datasets
    CIFAR10_training = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    CIFAR10_test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
      
    # create a training and a validation set by spliting training dataset to first 45000 and last 5000 indices
    num_train = len(CIFAR10_training)
    indices = list(range(num_train))
    train_idx, valid_idx = indices[:45000], indices[45000:]
    
    train_sampler = SubsetRandomSampler(train_idx) 
    validation_sampler = SubsetRandomSampler(valid_idx)
    
    train_dataloader = torch.utils.data.DataLoader(CIFAR10_training,batch_size=batch_size, sampler=train_sampler, num_workers=2)
    valid_dataloader = torch.utils.data.DataLoader(CIFAR10_training,batch_size=batch_size, sampler=validation_sampler, num_workers=2)
    test_dataloader = torch.utils.data.DataLoader(CIFAR10_test_set,batch_size=1, shuffle=False, num_workers=2)
    
    return train_dataloader, valid_dataloader, test_dataloader

# Part [2] TODO: Main model definition + any utilities such as weight initialization
class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(3, 12, kernel_size=5)       
    self.conv2 = nn.Conv2d(12, 48, kernel_size=5)      
    self.fc1 = nn.Linear(48 * 5 * 5, 260) 
    self.fc2 = nn.Linear(260, 120)
    self.fc3 = nn.Linear(120, 10)
    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
    
    # Xavier initialization
    torch.nn.init.xavier_normal_(self.conv1.weight)
    torch.nn.init.xavier_normal_(self.conv2.weight)
    torch.nn.init.xavier_normal_(self.fc1.weight)
    torch.nn.init.xavier_normal_(self.fc2.weight)
    torch.nn.init.xavier_normal_(self.fc3.weight)
    
  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = self.pool(x)
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = x.view(-1, 48 * 5 * 5)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = F.log_softmax(self.fc3(x))
    return x

# Part [3] TODO : Main trainig + validation, returns a trained model
def train(train_dataloader, valid_dataloader, device, config):
  
  # Import parameters from config
  lr = config['lr']
  momentum = config['momentum']
  num_epochs = config['num_epochs']
  regular_constant = config['regular_constant']
  log_interval = config['log_interval']
  
  # Setup model, loss function, and optimizer
  model = Net().to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=regular_constant)
  
  # Per Iterations training + validation
  for epoch in range(1, num_epochs + 1):
    # Training
    for batch_idx, (data, target) in enumerate(train_dataloader):
      data = data.to(device)
      target = target.to(device)
      # Forward -> Backprop -> Optimize
      optimizer.zero_grad()
      output = model(data)
      loss = criterion(output, target)
      #loss = F.nll_loss(output, target)
      loss.backward()
      optimizer.step()
      
      if batch_idx % log_interval == 0:
        print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
          epoch, batch_idx * len(data), len(train_dataloader.sampler),
          100. * batch_idx / len(train_dataloader), loss.item()))
    
    #Validation
    validation_loss = 0
    correct = 0
    with torch.no_grad():
      for data, target in valid_dataloader:
        data = data.to(device)
        target = target.to(device)
        output = model(data)
        validation_loss += criterion(output, target).item()
        #validation_loss += F.nll_loss(output, target, size_average=False).item()
        pred = output.data.max(1, keepdim=True)[1]
        correct += pred.eq(target.data.view_as(pred)).sum()
    validation_loss /= len(valid_dataloader.sampler)
    print('\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        validation_loss, correct, len(valid_dataloader.sampler),
        100. * correct / len(valid_dataloader.sampler)))
  
  return model

# Part [4] TODO: Testing + paramater setting
# TODO: Testing + paramater setting

def save_model_colab_for_submission(model):  # if you are running on colab
  drive.mount('/content/gdrive/', force_remount=True)
  
  torch.save(model.to(torch.device("cpu")), '/content/gdrive/My Drive/model.pt') # you will find the model in your home drive
  

def save_model_local_for_submission(model):  # if you are running on your local machine
  torch.save(model.to(torch.device("cpu")), 'model.pt')
  
def test(model, test_dataloader, device):
  test_predictions = []
  true_labels = []
  
  batch_size = 1
  i = 0
  test_loss = 0
  correct = 0
  criterion = nn.CrossEntropyLoss()
  
  with torch.no_grad():
    for data, target in test_dataloader:
      data = data.to(device)
      target = target.to(device)
      output = model(data)
      test_loss += criterion(output, target).item()
      #test_loss += F.nll_loss(output, target, size_average=False).item()
      pred = output.data.max(1, keepdim=True)[1]
      correct += pred.eq(target.data.view_as(pred)).sum()
      
      # update return lists by iterations
      test_predictions[i:i+batch_size] = pred
      true_labels[i:i+batch_size] = target.data.view_as(pred)
      i += batch_size
      
  test_loss /= len(test_dataloader.dataset)
  print('\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
    test_loss, correct, len(test_dataloader.dataset),
    100. * correct / len(test_dataloader.dataset)))

  return test_predictions, true_labels

def run_NN(dataset_name):
    # set parameters cifar10
  config = {
        'lr': 1e-2,
        'momentum': 0.9,
        'log_interval': 100,
        'num_epochs': 10,
        'batch_size': 200,
        'num_classes': 10,
        'regular_constant': 1e-4,
        'transforms': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) }
    
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  
  train_dataloader, valid_dataloader, test_dataloader = load_data(dataset_name, device, config)
  
  model = train(train_dataloader, valid_dataloader, device, config)
         
  device = torch.device("cpu")
  start_time = timeit.default_timer()
  preds, labels = test(model.to(device), test_dataloader, device)
  end_time = timeit.default_timer()
  

  test_time = (end_time - start_time)
  print("Total run time of testing the model: ", test_time , " seconds.")
  
  save_model_colab_for_submission(model)
  
  return preds, labels, test_time

"""Main loop. Run time and total score will be shown below."""

# Don't edit this cell
def run_on_dataset(dataset_name, filename):
    min_thres = 0.28
    max_thres = 0.38

    correct_predict, accuracy, run_time = run(run_NN, dataset_name, filename)

    score = compute_score(accuracy, min_thres, max_thres)
    result = OrderedDict(correct_predict=correct_predict,
                         accuracy=accuracy,
                         run_time=run_time)
    return result, score


def main():
    filenames = { "CIFAR10": "predictions_cifar10_YourName_IDNumber.txt"}
    result_all = OrderedDict()
    score_weights = [0.5]
    scores = []
    for dataset_name in ["CIFAR10"]:
        result_all, this_score = run_on_dataset(dataset_name, filenames[dataset_name])
    with open('result.txt', 'w') as f:
        f.writelines(pformat(result_all, indent=4))
    print("\nResult:\n", pformat(result_all, indent=4))


main()